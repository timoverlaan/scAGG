{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import joblib as jl\n",
    "\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_PATH = \"data/adata_rosmap_v3_top1000_s3_k30_drop_nout.h5ad\"  # Rosmap 1k\n",
    "# FILE_PATH = \"data/adata_rosmap_v3_top2000_k30_drop.h5ad\"  # Rosmap 2k\n",
    "FILE_PATH = \"data/adata_rosmap_v3_top5000_k30_drop.h5ad\"  # Rosmap 5k\n",
    "# FILE_PATH = \"data/adata_rosmap_v3_top8000_k30_drop.h5ad\"  # Rosmap 8k\n",
    "# FILE_PATH = \"\"  # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    adata_sc = ad.read_h5ad(FILE_PATH)\n",
    "\n",
    "    OUTLIERS = ['11326252', '11624423', '15114174', '15144878', '20147440', '20225925', '20730959', '50101785', '50105725', '50107583']\n",
    "    OUTLIERS = [int(x) for x in OUTLIERS]\n",
    "\n",
    "    DONORS = sorted(adata_sc.obs[\"Donor ID\"].unique())\n",
    "    DONORS = [x for x in DONORS if x not in OUTLIERS]\n",
    "    new_donors = []\n",
    "    donor_labels = []\n",
    "\n",
    "    N_CELLS = adata_sc[adata_sc.obs[\"Donor ID\"].isin(DONORS)].shape[0]\n",
    "\n",
    "    x = sp.lil_matrix((N_CELLS, adata_sc.shape[1]))\n",
    "    y = np.zeros(N_CELLS, dtype=int)\n",
    "    donor_ids = []\n",
    "    start_idx = 0\n",
    "\n",
    "    for i, donor in enumerate(tqdm(DONORS)):\n",
    "        adata_donor = adata_sc[adata_sc.obs[\"Donor ID\"] == donor]\n",
    "\n",
    "        # Get Wang labels\n",
    "        cogdx = adata_sc.obs[\"cogdx\"].loc[adata_donor.obs_names[0]]\n",
    "        braaksc = adata_sc.obs[\"braaksc\"].loc[adata_donor.obs_names[0]]\n",
    "        ceradsc = adata_sc.obs[\"ceradsc\"].loc[adata_donor.obs_names[0]]\n",
    "\n",
    "        if cogdx == 1 and braaksc <= 3 and ceradsc >= 3:\n",
    "            label = \"CT\"\n",
    "        elif cogdx == 4 and braaksc >= 4 and ceradsc <= 2:\n",
    "            label = \"AD\"\n",
    "        else:\n",
    "            label = \"Other\"\n",
    "\n",
    "        x[start_idx:start_idx + adata_donor.shape[0]] = adata_donor.X\n",
    "        if label == \"AD\":\n",
    "            y[start_idx:start_idx + adata_donor.shape[0]] = 1\n",
    "        \n",
    "        if label in [\"CT\", \"AD\"]:\n",
    "            start_idx += adata_donor.shape[0]\n",
    "            new_donors.append(donor)\n",
    "            donor_labels.append(label)\n",
    "            donor_ids.append([donor] * adata_donor.shape[0])\n",
    "        # Otherwise, skip this donor\n",
    "\n",
    "    x = x[:start_idx]  # Remove unused rows from the end\n",
    "    y = y[:start_idx]\n",
    "\n",
    "    x = x.tocsr()  # Convert to CSR format, for faster slicing\n",
    "    donor_ids = np.concatenate(donor_ids)\n",
    "\n",
    "    del adata_sc, adata_donor\n",
    "    return x, y, new_donors, donor_labels, donor_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [11:01<00:00,  1.95s/it]"
     ]
    }
   ],
   "source": [
    "# Cache the new data\n",
    "file_basename = FILE_PATH.split('/')[-1].replace('.h5ad', '.joblib')\n",
    "\n",
    "if os.path.exists(f\"data/cache/{file_basename}\"):\n",
    "    x, y, new_donors, donor_labels, donor_ids = jl.load(f\"data/cache/{file_basename}\")\n",
    "else:\n",
    "    x, y, new_donors, donor_labels, donor_ids = load_data()\n",
    "    # jl.dump((x, y, new_donors, donor_labels, donor_ids), f\"data/cache/{file_basename}\")\n",
    "\n",
    "# x, y, new_donors, donor_labels, donor_ids = jl.load(file_basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 10\n",
    "N_FOLDS = 5\n",
    "SPLIT_SEED = None\n",
    "# SPLIT_SEED = 42\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "mean_acc_cell = np.zeros(N_RUNS)\n",
    "mean_prec_cell = np.zeros(N_RUNS)\n",
    "mean_rec_cell = np.zeros(N_RUNS)\n",
    "mean_f1_cell = np.zeros(N_RUNS)\n",
    "mean_auc_cell = np.zeros(N_RUNS)\n",
    "\n",
    "mean_acc_donor = np.zeros(N_RUNS)\n",
    "mean_prec_donor = np.zeros(N_RUNS)\n",
    "mean_rec_donor = np.zeros(N_RUNS)\n",
    "mean_f1_donor = np.zeros(N_RUNS)\n",
    "mean_auc_donor = np.zeros(N_RUNS)\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for j in range(N_RUNS):\n",
    "    print(f\"Run {j+1}/{N_RUNS}\")\n",
    "\n",
    "    if SPLIT_SEED is not None:\n",
    "        kf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SPLIT_SEED)\n",
    "    else:\n",
    "        kf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True)\n",
    "\n",
    "    test_acc_cell = []\n",
    "    test_acc_donor = []\n",
    "    test_prec_cell = []\n",
    "    test_prec_donor = []\n",
    "    test_rec_cell = []\n",
    "    test_rec_donor = []\n",
    "    test_f1_cell = []\n",
    "    test_f1_donor = []\n",
    "    test_auc_cell = []\n",
    "    test_auc_donor = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(new_donors, donor_labels)):\n",
    "        # print(f\"Fold {i+1}/{N_FOLDS}\")\n",
    "\n",
    "        # Train/test split\n",
    "        train_donors = [new_donors[donor_idx] for donor_idx in train_index]\n",
    "        test_donors = [new_donors[donor_idx] for donor_idx in test_index]\n",
    "        x_train = x[np.isin(donor_ids, train_donors)]\n",
    "        y_train = y[np.isin(donor_ids, train_donors)]    \n",
    "        x_test = x[np.isin(donor_ids, test_donors)]\n",
    "        y_test = y[np.isin(donor_ids, test_donors)]\n",
    "        \n",
    "        # Model definition\n",
    "        model = Lasso(alpha=0.03)\n",
    "\n",
    "        # Model training\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # Model evaluation\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        y_pred_test = model.predict(x_test)\n",
    "\n",
    "        test_auc_cell.append(roc_auc_score(y_test, y_pred_test))\n",
    "        \n",
    "        y_pred_train = (y_pred_train > 0.5).astype(int)\n",
    "        y_pred_test = (y_pred_test > 0.5).astype(int)\n",
    "                \n",
    "        # Metrics per cell\n",
    "        acc_train = (y_pred_train == y_train).mean()\n",
    "        acc_test = (y_pred_test == y_test).mean()\n",
    "    \n",
    "        test_acc_cell.append(accuracy_score(y_test, y_pred_test))\n",
    "        test_prec_cell.append(precision_score(y_test, y_pred_test))\n",
    "        test_rec_cell.append(recall_score(y_test, y_pred_test))\n",
    "        test_f1_cell.append(f1_score(y_test, y_pred_test))\n",
    "    \n",
    "        # But now we want to aggregate predictions per donor\n",
    "        donor_pred = []\n",
    "        donor_true = []\n",
    "        test_donor_ids = np.array(donor_ids)[np.isin(donor_ids, test_donors)]\n",
    "        for donor in test_donors:\n",
    "            idx = np.isin(test_donor_ids, donor)\n",
    "            donor_pred.append(y_pred_test[idx].mean())\n",
    "            donor_true.append(y_test[idx].mean())\n",
    "        donor_pred = np.array(donor_pred)\n",
    "        donor_true = np.array(donor_true)\n",
    "\n",
    "        # Also for training data \n",
    "        donor_pred_train = []\n",
    "        donor_true_train = []\n",
    "        train_donor_ids = np.array(donor_ids)[np.isin(donor_ids, train_donors)]\n",
    "        for donor in train_donors:\n",
    "            idx = np.isin(train_donor_ids, donor)\n",
    "            donor_pred_train.append(y_pred_train[idx].mean())\n",
    "            donor_true_train.append(y_train[idx].mean())\n",
    "        donor_pred_train = np.array(donor_pred_train)\n",
    "        donor_true_train = np.array(donor_true_train)\n",
    "\n",
    "        # Pick best threshold based on training data:\n",
    "        thresholds = np.linspace(0, 1, 101)\n",
    "        best_threshold = 0\n",
    "        best_acc = 0\n",
    "        for threshold in thresholds:\n",
    "            donor_pred_train_ = (donor_pred_train > threshold).astype(int)\n",
    "            acc = accuracy_score(donor_true_train, donor_pred_train_)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_threshold = threshold\n",
    "\n",
    "\n",
    "        # Metrics per donor\n",
    "        test_auc_donor.append(roc_auc_score(donor_true, donor_pred))\n",
    "        donor_pred = (donor_pred > best_threshold).astype(int)\n",
    "\n",
    "        test_acc_donor.append(accuracy_score(donor_true, donor_pred))\n",
    "        test_prec_donor.append(precision_score(donor_true, donor_pred))\n",
    "        test_rec_donor.append(recall_score(donor_true, donor_pred))\n",
    "        test_f1_donor.append(f1_score(donor_true, donor_pred))\n",
    "\n",
    "        # print(\"With best threshold (gridsearch):\")\n",
    "        # print(f\"acc  (cell) = {test_acc_cell[-1]:.4f}, acc  (donor) = {test_acc_donor[-1]:.4f}\")\n",
    "        # print(f\"prec (cell) = {test_prec_cell[-1]:.4f}, prec (donor) = {test_prec_donor[-1]:.4f}\")\n",
    "        # print(f\"rec  (cell) = {test_rec_cell[-1]:.4f}, rec  (donor) = {test_rec_donor[-1]:.4f}\")\n",
    "        # print(f\"f1   (cell) = {test_f1_cell[-1]:.4f}, f1   (donor) = {test_f1_donor[-1]:.4f}\")\n",
    "        # print(f\"auc  (cell) = {test_auc_cell[-1]:.4f}, auc  (donor) = {test_auc_donor[-1]:.4f}\")\n",
    "\n",
    "\n",
    "    mean_acc_cell[j] = np.mean(test_acc_cell)\n",
    "    mean_prec_cell[j] = np.mean(test_prec_cell)\n",
    "    mean_rec_cell[j] = np.mean(test_rec_cell)\n",
    "    mean_f1_cell[j] = np.mean(test_f1_cell)\n",
    "    mean_auc_cell[j] = np.mean(test_auc_cell)\n",
    "\n",
    "    mean_acc_donor[j] = np.mean(test_acc_donor)\n",
    "    mean_prec_donor[j] = np.mean(test_prec_donor)\n",
    "    mean_rec_donor[j] = np.mean(test_rec_donor)\n",
    "    mean_f1_donor[j] = np.mean(test_f1_donor)\n",
    "    mean_auc_donor[j] = np.mean(test_auc_donor)\n",
    "    \n",
    "print(f\"Mean test  acc (cell): {np.mean(mean_acc_cell):.4f} +/- {np.std(mean_acc_cell):.4f}\")\n",
    "print(f\"Mean test prec (cell): {np.mean(mean_prec_cell):.4f} +/- {np.std(mean_prec_cell):.4f}\")\n",
    "print(f\"Mean test  rec (cell): {np.mean(mean_rec_cell):.4f} +/- {np.std(mean_rec_cell):.4f}\")\n",
    "print(f\"Mean test   f1 (cell): {np.mean(mean_f1_cell):.4f} +/- {np.std(mean_f1_cell):.4f}\")\n",
    "print(f\"Mean test  auc (cell): {np.mean(mean_auc_cell):.4f} +/- {np.std(mean_auc_cell):.4f}\")\n",
    "\n",
    "print(\"\\nPer donor:\")\n",
    "print(f\"Mean test  acc: {np.mean(mean_acc_donor):.4f} +/- {np.std(mean_acc_donor):.4f}\")\n",
    "print(f\"Mean test prec: {np.mean(mean_prec_donor):.4f} +/- {np.std(mean_prec_donor):.4f}\")\n",
    "print(f\"Mean test  rec: {np.mean(mean_rec_donor):.4f} +/- {np.std(mean_rec_donor):.4f}\")\n",
    "print(f\"Mean test   f1: {np.mean(mean_f1_donor):.4f} +/- {np.std(mean_f1_donor):.4f}\")\n",
    "print(f\"Mean test  auc: {np.mean(mean_auc_donor):.4f} +/- {np.std(mean_auc_donor):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "**LASSO (alpha=0.03), 1k genes**\n",
    "```\n",
    "100%|██████████| 10/10 [08:49<00:00, 52.93s/it]\n",
    "Mean test  acc (cell): 0.5503 +/- 0.0079\n",
    "Mean test prec (cell): 0.5618 +/- 0.0053\n",
    "Mean test  rec (cell): 0.7893 +/- 0.0142\n",
    "Mean test   f1 (cell): 0.6521 +/- 0.0066\n",
    "Mean test  auc (cell): 0.5726 +/- 0.0119\n",
    "\n",
    "Per donor:\n",
    "Mean test  acc: 0.5989 +/- 0.0309\n",
    "Mean test prec: 0.6176 +/- 0.0242\n",
    "Mean test  rec: 0.7662 +/- 0.0628\n",
    "Mean test   f1: 0.6677 +/- 0.0445\n",
    "Mean test  auc: 0.6325 +/- 0.0120\n",
    "```\n",
    "\n",
    "**LASSO (alpha=0.03), 2k genes**\n",
    "```\n",
    "Mean test  acc (cell): 0.5238 +/- 0.0099\n",
    "Mean test prec (cell): 0.5410 +/- 0.0062\n",
    "Mean test  rec (cell): 0.9025 +/- 0.0355\n",
    "Mean test   f1 (cell): 0.6656 +/- 0.0146\n",
    "Mean test  auc (cell): 0.5740 +/- 0.0075\n",
    "\n",
    "Per donor:\n",
    "Mean test  acc: 0.5568 +/- 0.0111\n",
    "Mean test prec: 0.5694 +/- 0.0124\n",
    "Mean test  rec: 0.8934 +/- 0.0451\n",
    "Mean test   f1: 0.6872 +/- 0.0140\n",
    "Mean test  auc: 0.5219 +/- 0.0201\n",
    "```\n",
    "\n",
    "**LASSO (alpha=0.03), 5k genes**\n",
    "```\n",
    "Mean test  acc (cell): 0.5406 +/- 0.0045\n",
    "Mean test prec (cell): 0.5496 +/- 0.0034\n",
    "Mean test  rec (cell): 0.8722 +/- 0.0164\n",
    "Mean test   f1 (cell): 0.6690 +/- 0.0053\n",
    "Mean test  auc (cell): 0.5680 +/- 0.0098\n",
    "\n",
    "Per donor:\n",
    "Mean test  acc: 0.5949 +/- 0.0119\n",
    "Mean test prec: 0.6003 +/- 0.0111\n",
    "Mean test  rec: 0.8609 +/- 0.0436\n",
    "Mean test   f1: 0.7006 +/- 0.0146\n",
    "Mean test  auc: 0.5764 +/- 0.0200\n",
    "```\n",
    "\n",
    "**LASSO (alpha=0.03), 8k genes**\n",
    "... cancelled due to time limit. Is now running again as job 11062857"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
